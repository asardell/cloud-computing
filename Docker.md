# Docker ğŸ³

<p align="center">
  <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Docker_%28container_engine%29_logo.svg/1280px-Docker_%28container_engine%29_logo.svg.png" alt="Source de l'image" width="600"/>
</p>

- [Docker ğŸ³](#docker-)
- [Comprendre Docker et la notion de conteneurs](#comprendre-docker-et-la-notion-de-conteneurs)
    - [Introduction](#introduction)
    - [PrÃ© requis](#prÃ©-requis)
    - [VÃ©rifier lâ€™installation](#vÃ©rifier-linstallation)
    - [TÃ©lÃ©charger une image lÃ©gÃ¨re](#tÃ©lÃ©charger-une-image-lÃ©gÃ¨re)
    - [ExÃ©cuter un conteneur simple](#exÃ©cuter-un-conteneur-simple)
    - [Conteneur interactif](#conteneur-interactif)
    - [CrÃ©er plusieurs conteneurs Ã  partir de la mÃªme image](#crÃ©er-plusieurs-conteneurs-Ã -partir-de-la-mÃªme-image)
    - [Isolation des conteneurs](#isolation-des-conteneurs)
    - [ExÃ©cuter une commande dans un conteneur existant](#exÃ©cuter-une-commande-dans-un-conteneur-existant)
    - [Nettoyer les conteneurs](#nettoyer-les-conteneurs)
    - [Points clÃ©s Ã  retenir](#points-clÃ©s-Ã -retenir)
  - [Tableau rÃ©capitulatif des commandes Docker](#tableau-rÃ©capitulatif-des-commandes-docker)
  - [Liens utiles](#liens-utiles)
- [Installer Docker sur Windows et comprendre ses composants](#installer-docker-sur-windows-et-comprendre-ses-composants)
  - [Installer Docker Desktop](#installer-docker-desktop)
    - [VÃ©rification](#vÃ©rification)
  - [RÃ´le de Docker Desktop](#rÃ´le-de-docker-desktop)
  - [WSL 2 (Windows Subsystem for Linux)](#wsl-2-windows-subsystem-for-linux)
  - [Pourquoi utiliser Docker sur Windows ?](#pourquoi-utiliser-docker-sur-windows-)
- [Construire une image existante avec interface graphique](#construire-une-image-existante-avec-interface-graphique)
  - [Objectif](#objectif)
  - [PrÃ©-requis](#prÃ©-requis-1)
  - [Pourquoi plutÃ´t Docker ?](#pourquoi-plutÃ´t-docker-)
  - [Streamlit](#streamlit)
    - [CrÃ©er lâ€™application Streamlit](#crÃ©er-lapplication-streamlit)
    - [CrÃ©er le Dockerfile](#crÃ©er-le-dockerfile)
    - [Construire lâ€™image Docker](#construire-limage-docker)
    - [Lancer le conteneur](#lancer-le-conteneur)
    - [En rÃ©sumÃ©](#en-rÃ©sumÃ©)
    - [Supprimer le conteneur](#supprimer-le-conteneur)
    - [Tableau rÃ©capitulatif des commandes](#tableau-rÃ©capitulatif-des-commandes)
    - [ğŸ’¡ Astuces](#-astuces)
- [Quelques notions de RÃ©seau](#quelques-notions-de-rÃ©seau)
  - [La notion de port sur un PC :](#la-notion-de-port-sur-un-pc-)
  - [Les ports sur le web et en localhost](#les-ports-sur-le-web-et-en-localhost)
    - [En gros](#en-gros)
    - [SchÃ©ma rÃ©capitulatif](#schÃ©ma-rÃ©capitulatif)
- [Gestion des volumes Docker](#gestion-des-volumes-docker)
  - [Pourquoi utiliser des volumes ?](#pourquoi-utiliser-des-volumes-)
  - [Types de stockage](#types-de-stockage)
    - [Volumes nommÃ©s](#volumes-nommÃ©s)
    - [Bind mounts (montage de rÃ©pertoire hÃ´te)](#bind-mounts-montage-de-rÃ©pertoire-hÃ´te)
  - [Commandes utiles](#commandes-utiles)
    - [CrÃ©er un volume](#crÃ©er-un-volume)
    - [Lister les volumes](#lister-les-volumes)
    - [Inspecter un volume](#inspecter-un-volume)
    - [Supprimer un volume](#supprimer-un-volume)
  - [Gestion des volumes Docker avec des fichiers CSV](#gestion-des-volumes-docker-avec-des-fichiers-csv)
    - [Arborescence du projet](#arborescence-du-projet)
    - [PrÃ©parer un script Python](#prÃ©parer-un-script-python)
    - [CrÃ©er un fichier Dockerfile](#crÃ©er-un-fichier-dockerfile)
    - [CrÃ©er et monter un volume Docker](#crÃ©er-et-monter-un-volume-docker)
    - [Construire lâ€™image Docker](#construire-limage-docker-1)
    - [Lancer le conteneur pour gÃ©nÃ©rer le CSV](#lancer-le-conteneur-pour-gÃ©nÃ©rer-le-csv)
    - [VÃ©rifier la persistance](#vÃ©rifier-la-persistance)
    - [Lister les fichiers dans un volume nommÃ©](#lister-les-fichiers-dans-un-volume-nommÃ©)
    - [Explorer le volume en mode interactif](#explorer-le-volume-en-mode-interactif)
    - [Bonnes pratiques](#bonnes-pratiques)
  - [GÃ©nÃ©rer un CSV avec Docker et monter un dossier local](#gÃ©nÃ©rer-un-csv-avec-docker-et-monter-un-dossier-local)
    - [Modifier le script `generate_csv.py`](#modifier-le-script-generate_csvpy)
    - [PrÃ©parer un dossier local pour stocker les CSV](#prÃ©parer-un-dossier-local-pour-stocker-les-csv)
    - [Construire lâ€™image Docker](#construire-limage-docker-2)
    - [Lancer le conteneur Python avec un bind mount](#lancer-le-conteneur-python-avec-un-bind-mount)
    - [VÃ©rifier le fichier sur lâ€™hÃ´te](#vÃ©rifier-le-fichier-sur-lhÃ´te)
- [Introduction Ã  Docker Compose](#introduction-Ã -docker-compose)
  - [Objectif](#objectif-1)
  - [Arborescence du projet](#arborescence-du-projet-1)
  - [Fichier app.py](#fichier-apppy)
  - [Fichier requirements.txt](#fichier-requirementstxt)
  - [Fichier Dockerfile](#fichier-dockerfile)
  - [Fichier docker-compose.yml](#fichier-docker-composeyml)
  - [CrÃ©er la table MySQL](#crÃ©er-la-table-mysql)
  - [Lancer toute lâ€™application](#lancer-toute-lapplication)
  - [VÃ©rifier les donnÃ©es](#vÃ©rifier-les-donnÃ©es)
  - [Nettoyer](#nettoyer)
- [Introduction Ã  Docker Swarm Mode](#introduction-Ã -docker-swarm-mode)
  - [DÃ©couverte](#dÃ©couverte)
  - [Docker Swarm Mode : quâ€™est-ce que câ€™est ?](#docker-swarm-mode--quest-ce-que-cest-)
    - [RÃ´les des nÅ“uds](#rÃ´les-des-nÅ“uds)
    - [IntÃ©rÃªt](#intÃ©rÃªt)
  - [DÃ©ploiement et Scaling dâ€™un Service Web](#dÃ©ploiement-et-scaling-dun-service-web)
    - [Objectif](#objectif-2)
    - [Lancer lâ€™environnement](#lancer-lenvironnement)
    - [Initialiser le Swarm](#initialiser-le-swarm)
    - [VÃ©rifier les nÅ“uds du cluster](#vÃ©rifier-les-nÅ“uds-du-cluster)
    - [CrÃ©er un service web](#crÃ©er-un-service-web)
    - [Tester le service](#tester-le-service)
    - [Scaler (augmenter le nombre dâ€™instances)](#scaler-augmenter-le-nombre-dinstances)
    - [Load Balancing Automatique](#load-balancing-automatique)
    - [TolÃ©rance aux pannes](#tolÃ©rance-aux-pannes)
    - [RÃ©duire le nombre dâ€™instances](#rÃ©duire-le-nombre-dinstances)
    - [ComprÃ©hension du fonctionnement](#comprÃ©hension-du-fonctionnement)
      - [Swarm = un cluster de serveurs Docker](#swarm--un-cluster-de-serveurs-docker)
      - [Service = application distribuÃ©e](#service--application-distribuÃ©e)
      - [Scaling = augmenter la capacitÃ©](#scaling--augmenter-la-capacitÃ©)
      - [Load Balancing intÃ©grÃ©](#load-balancing-intÃ©grÃ©)
      - [RÃ©silience](#rÃ©silience)
      - [Supprimer le service](#supprimer-le-service)
    - [En rÃ©sumÃ©](#en-rÃ©sumÃ©-1)
    - [Exemple visuel](#exemple-visuel)
    - [Ã€ retenir](#Ã -retenir)
  - [Formulaire Web Streamlit + MySQL  avec Play With Docker](#formulaire-web-streamlit--mysql--avec-play-with-docker)
    - [Objectif](#objectif-3)
    - [PrÃ©parer lâ€™environnement PWD](#prÃ©parer-lenvironnement-pwd)
    - [CrÃ©er un rÃ©seau overlay](#crÃ©er-un-rÃ©seau-overlay)
    - [DÃ©ployer MySQL](#dÃ©ployer-mysql)
    - [PrÃ©parer lâ€™application Streamlit](#prÃ©parer-lapplication-streamlit)
      - [CrÃ©er `app.py`](#crÃ©er-apppy)
      - [CrÃ©er `requirements.txt`](#crÃ©er-requirementstxt)
      - [CrÃ©er `Dockerfile`](#crÃ©er-dockerfile)
    - [Construire lâ€™image Streamlit](#construire-limage-streamlit)
    - [DÃ©ployer le service Streamlit sur le Swarm](#dÃ©ployer-le-service-streamlit-sur-le-swarm)
    - [Tester lâ€™application](#tester-lapplication)
    - [Nettoyer](#nettoyer-1)
    - [Conseils PWD](#conseils-pwd)
    - [SchÃ©ma visuel du TP](#schÃ©ma-visuel-du-tp)
- [Mini-projet Docker : Extraction des donnÃ©es DPE par dÃ©partement](#mini-projet-docker--extraction-des-donnÃ©es-dpe-par-dÃ©partement)
  - [Objectif pÃ©dagogique](#objectif-pÃ©dagogique)
  - [Consignes gÃ©nÃ©rales](#consignes-gÃ©nÃ©rales)
  - [Livrables attendus](#livrables-attendus)
  - [Points pÃ©dagogiques visÃ©s](#points-pÃ©dagogiques-visÃ©s)

# Comprendre Docker et la notion de conteneurs

**Objectif :** DÃ©couvrir Docker, manipuler des images et conteneurs, crÃ©er plusieurs instances, gÃ©rer lâ€™isolation et nettoyer les conteneurs.

### Introduction

**Pourquoi Docker ?**  

Docker est une technologie de conteneurisation qui permet de **packager une application et toutes ses dÃ©pendances** dans un environnement lÃ©ger et isolÃ© appelÃ© *conteneur*. Contrairement aux machines virtuelles qui virtualisent le hardware complet, Docker fonctionne au niveau applicatif, ce qui le rend **rapide et efficace en ressources**.

**En entreprise :**

- **DÃ©ploiement rapide dâ€™applications** : vos Ã©quipes peuvent lancer une application sur nâ€™importe quelle machine sans se soucier des diffÃ©rences de configuration.  
- **Isolation et sÃ©curitÃ©** : chaque application tourne dans son propre conteneur, Ã©vitant les conflits avec dâ€™autres services.  
- **ReproductibilitÃ©** : ce qui fonctionne sur votre machine fonctionne exactement de la mÃªme maniÃ¨re sur un serveur ou en production.  

**Exemples orientÃ©s Data :**

- DÃ©ployer rapidement un **serveur PostgreSQL ou MySQL** dans un conteneur pour tester des pipelines de donnÃ©es.  
- Lancer des **jobs Python ou R** avec toutes les librairies nÃ©cessaires prÃ©installÃ©es (pandas, numpy, scikit-learn, etc.) sans polluer votre machine locale.  
- Tester des outils comme **Kafka, Airflow, Spark ou MinIO** dans des conteneurs pour construire et orchestrer des pipelines de donnÃ©es.  
- Faciliter la collaboration : chaque membre de lâ€™Ã©quipe peut exÃ©cuter exactement les mÃªmes conteneurs, assurant la **cohÃ©rence des environnements**.  

:bulb: En rÃ©sumÃ©, Docker permet de travailler plus vite, plus proprement et de maniÃ¨re reproductible, ce qui est **indispensable dans les projets data modernes** oÃ¹ plusieurs outils et services doivent coexister.

### PrÃ© requis

- CrÃ©er un compte sur Docker Hub : [https://hub.docker.com](https://hub.docker.com)  
  *Cela permettra de tÃ©lÃ©charger des images et d'utiliser les labs en ligne docker.*  
- Aller sur [Play with Docker](https://labs.play-with-docker.com/)  
  *Environnement gratuit en ligne pour tester Docker sans installation locale.*  
- CrÃ©er une instance sur Play with Docker  
  *Chaque instance est un mini serveur Linux oÃ¹ vous pourrez lancer vos conteneurs.*

:warning: Dans la console de **Play With Docker (PWD)** :  

- **Copier** : `CTRL + INSERT`  
- **Coller** : `SHIFT + INSERT`  

Contrairement aux raccourcis classiques (CTRL+C / CTRL+V), ces combinaisons fonctionnent directement dans les terminaux PWD pour Ã©viter les conflits avec les commandes shell.

### VÃ©rifier lâ€™installation

Assurez-vous que Docker fonctionne en tapant `docker version` et `docker info`.  

```bash
docker version
docker info
```

Test rapide avec lâ€™image de test :

```bash
docker container run hello-world
```

- Docker cherche lâ€™image `hello-world` localement.  
- Si elle nâ€™existe pas, elle est tÃ©lÃ©chargÃ©e depuis Docker Hub avec 
```bash
docker pull hello-world:latest
docker container run hello-world
```
- Le conteneur sâ€™exÃ©cute, affiche un message, puis se ferme automatiquement.

### TÃ©lÃ©charger une image lÃ©gÃ¨re

TÃ©lÃ©chargez lâ€™image Alpine Linux (trÃ¨s lÃ©gÃ¨re) :

```bash
docker image pull alpine:latest
```

:bulb: Alpine est une **image Docker trÃ¨s lÃ©gÃ¨re** basÃ©e sur Linux.  

- Taille : â‰ˆ 5 Mo â†’ trÃ¨s rapide Ã  tÃ©lÃ©charger et dÃ©marrer  
- Contient uniquement lâ€™essentiel pour exÃ©cuter des commandes Linux  
- IdÃ©ale pour tester des services simples ou lancer des scripts courts  
- Moins de dÃ©pendances et donc moins de risques de bugs ou failles  

Dans ce TP, on utilise Alpine pour crÃ©er des containers lÃ©gers qui dorment ou communiquent entre eux sans surcharger le cluster.

Listez les images locales avec `docker image ls`.  

```bash
docker image ls
```

Les colonnes importantes sont : `REPOSITORY` (nom de lâ€™image), `TAG` (version), `IMAGE ID` (identifiant unique) et `SIZE` (taille).

### ExÃ©cuter un conteneur simple

Lister les fichiers Ã  lâ€™intÃ©rieur dâ€™Alpine :

```bash
docker container run alpine ls -l
```
Chaque commande `run` crÃ©e un nouveau conteneur Ã©phÃ©mÃ¨re qui sâ€™arrÃªte aprÃ¨s lâ€™exÃ©cution.

### Conteneur interactif

Au lieu d'exÃ©cuter une commande directement avec `docker container run alpine ls -l`, il est aussi possible **dâ€™entrer dans le conteneur** pour lancer `ls` (ou dâ€™autres commandes) depuis lâ€™intÃ©rieur.

1) Lancer un conteneur en mode interactif

On peut dÃ©marrer un conteneur avec un shell :

```bash
docker run -it alpine sh
```

2) Une fois Ã  lâ€™intÃ©rieur, il suffit dâ€™utiliser la commande :

```bash
ls -l
```

Ã€ lâ€™intÃ©rieur, on peut tester des commandes comme `ls -l` , `uname -a`, `mkdir toto`, etc.  

3) Pour sortir du conteneur :

```bash
exit
```

### CrÃ©er plusieurs conteneurs Ã  partir de la mÃªme image

- Conteneur 1 :
 
```bash
docker container run alpine
```

- Conteneur 2 :  

```bash
docker container run alpine
```

- Conteneur 3 : crÃ©er un fichier dans le containeur

```bash
docker container run -it alpine /bin/sh
echo "hello world" > hello.txt
ls
exit
```


VÃ©rifiez tous les conteneurs existants (y compris arrÃªtÃ©s) avec `docker container ls -a`.

```bash
docker container ls -a
```

### Isolation des conteneurs

Si vous relancez un nouveau conteneur Alpine et tapez `ls`, vous ne verrez pas `hello.txt`.  
- Chaque conteneur est isolÃ©.  
- Les fichiers et modifications dâ€™un conteneur ne sont pas visibles dans un autre conteneur.

### ExÃ©cuter une commande dans un conteneur existant

Pour voir le contenu de `hello.txt` dans le conteneur oÃ¹ il a Ã©tÃ© crÃ©Ã© :  

- RedÃ©marrer le conteneur avec `docker container start -i <container_id>`  
- Lister les fichiers : `ls`  
- Lire le contenu : `cat hello.txt`

```bash
docker container start -i <container_id>
ls
cat hello.txt
exit
```

### Nettoyer les conteneurs

Lister les conteneurs actifs :

```bash
docker container ls
```

Lister tous les conteneurs :

```bash
docker container ls -a
```

Pour arrÃªter un conteneur actif :

```bash
docker container kill <container_id>
```

Pour supprimer un conteneur arrÃªtÃ© :  

```bash
docker container rm <container_id>
```

### Points clÃ©s Ã  retenir

- Une **image** est un modÃ¨le figÃ© contenant un OS et des dÃ©pendances.  
- Un **conteneur** est une instance en cours dâ€™exÃ©cution de cette image.  
- Les conteneurs sont **Ã©phÃ©mÃ¨res** et **isolÃ©s**.  
- Docker est rapide car il fonctionne au niveau applicatif, contrairement aux VM qui virtualisent le hardware.  
- Les images par dÃ©faut proviennent de **Docker Hub**, mais vous pouvez en utiliser dâ€™autres.  


## Tableau rÃ©capitulatif des commandes Docker

| Commande | Description |
|----------|-------------|
| `docker version` | Affiche la version du client et du serveur Docker |
| `docker info` | Affiche les informations dÃ©taillÃ©es sur lâ€™installation Docker |
| `docker container run hello-world` | TÃ©lÃ©charge (si nÃ©cessaire) et exÃ©cute le conteneur de test "hello-world" |
| `docker image pull alpine` | TÃ©lÃ©charge lâ€™image Alpine Linux depuis Docker Hub |
| `docker image ls` | Liste toutes les images Docker prÃ©sentes localement |
| `docker container run alpine ls -l` | ExÃ©cute la commande `ls -l` dans un nouveau conteneur Alpine |
| `docker container run alpine echo "hello from alpine"` | ExÃ©cute la commande `echo` dans un nouveau conteneur Alpine |
| `docker container run -it alpine /bin/sh` | Lance un conteneur Alpine en mode interactif avec un shell |
| `docker container ls` | Liste les conteneurs en cours dâ€™exÃ©cution |
| `docker container ls -a` | Liste tous les conteneurs, mÃªme ceux arrÃªtÃ©s |
| `docker container start -i <container_id>` | RedÃ©marre un conteneur existant et ouvre un shell interactif |
| `docker container exec <container_id> <commande>` | ExÃ©cute une commande dans un conteneur en cours dâ€™exÃ©cution |
| `docker container kill <container_id>` | ArrÃªte immÃ©diatement un conteneur actif |
| `docker container rm <container_id>` | Supprime un conteneur arrÃªtÃ© |
| `cat hello.txt` | Affiche le contenu du fichier `hello.txt` Ã  lâ€™intÃ©rieur du conteneur |
| `ls` | Liste les fichiers/dossiers Ã  lâ€™intÃ©rieur du conteneur |
| `echo "texte" > hello.txt` | CrÃ©e un fichier `hello.txt` contenant le texte "texte" Ã  lâ€™intÃ©rieur du conteneur |

## Liens utiles

- [Tutoriel Docker](https://training.play-with-docker.com/)
- [Docker Hub](https://www.docker.com/)
- [Play with docker](https://labs.play-with-docker.com/)

# Installer Docker sur Windows et comprendre ses composants

Docker permet de crÃ©er et exÃ©cuter des conteneurs pour isoler des applications et leurs dÃ©pendances. Sur Windows, il est recommandÃ© dâ€™utiliser **Docker Desktop** pour simplifier lâ€™installation et la gestion des conteneurs.


## Installer Docker Desktop

1. TÃ©lÃ©charger Docker Desktop depuis le site officiel :  
   [https://www.docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop)

2. Lancer lâ€™installateur et suivre les Ã©tapes.

3. RedÃ©marrer lâ€™ordinateur si nÃ©cessaire.

### VÃ©rification

Ouvrir PowerShell ou lâ€™invite de commandes et taper :  
```shell
docker --version
docker compose version
```

Si Docker rÃ©pond, lâ€™installation est rÃ©ussie.

## RÃ´le de Docker Desktop

- Fournit une **interface graphique** pour gÃ©rer les conteneurs et images.  
- Installe et configure automatiquement **le moteur Docker (Docker Engine)** sur Windows.  
- IntÃ¨gre **Docker CLI** et **Docker Compose** pour travailler en ligne de commande.  
- Simplifie la configuration rÃ©seau et le partage de fichiers avec Windows.

## WSL 2 (Windows Subsystem for Linux)

Docker Desktop sur Windows fonctionne gÃ©nÃ©ralement avec **WSL 2**, un sous-systÃ¨me Linux intÃ©grÃ© Ã  Windows :

- Permet dâ€™exÃ©cuter un noyau Linux complet sur Windows.  
- Les conteneurs Docker sâ€™exÃ©cutent dans cet environnement Linux pour plus de compatibilitÃ©.  
- NÃ©cessite lâ€™activation de WSL 2 dans les fonctionnalitÃ©s Windows et lâ€™installation dâ€™une distribution Linux (Ubuntu par exemple).

## Pourquoi utiliser Docker sur Windows ?

- DÃ©velopper et tester des applications dans un environnement **identique Ã  Linux**.  
- Isoler les projets pour Ã©viter les conflits de dÃ©pendances.  
- Simplifier le dÃ©ploiement dâ€™applications sur dâ€™autres machines ou serveurs.  
- Travailler avec Docker Compose pour orchestrer plusieurs conteneurs facilement.

# Construire une image existante avec interface graphique

## Objectif

Apprendre Ã  manipuler Docker avec une application Streamlit, crÃ©er un conteneur, lâ€™exÃ©cuter sur un port exposÃ©, et gÃ©rer ses conteneurs.  
Le projet est lÃ©ger et adaptÃ© Ã  une VM de 4â€¯Go.

## PrÃ©-requis

- CrÃ©er un compte sur Docker Hub : [https://hub.docker.com](https://hub.docker.com)  
  *Cela permettra de tÃ©lÃ©charger des images et d'utiliser les labs en ligne Docker.*
- Aller sur [Play With Docker](https://labs.play-with-docker.com/)  
  *Environnement gratuit en ligne pour tester Docker sans installation locale.*
- CrÃ©er une instance sur Play With Docker  
  *Chaque instance est un mini serveur Linux oÃ¹ vous pourrez lancer vos conteneurs.*

## Pourquoi plutÃ´t Docker ?

- Permet de **packager des applications avec toutes leurs dÃ©pendances**  
- TrÃ¨s utilisÃ© en entreprise pour les **pipelines data**, les **microservices**, ou le **dÃ©ploiement rapide**  
- Exemple Data : visualiser un dashboard web lÃ©ger ou exÃ©cuter un modÃ¨le ML dans un conteneur isolÃ©  

## Streamlit

<p align="center">
  <img src="https://streamlit.io/images/brand/streamlit-logo-secondary-colormark-darktext.png" alt="Source de l'image" width="600"/>
</p>

### CrÃ©er lâ€™application Streamlit

1. Dans le terminal, crÃ©ez un dossier pour lâ€™application :  

```bash
mkdir streamlit_app
cd streamlit_app
```

2. CrÃ©ez le fichier **app.py** :  

```bash
echo "import streamlit as st
st.title('Hello Docker!')
st.write('Ceci est une app Streamlit dans un conteneur Docker')
st.line_chart({'data': [1, 3, 2, 4, 5, 3]})
" > app.py
```

:warning:  VÃ©rifier lâ€™encodage de `app.py`
 - **VSCode** :
   - Ouvre `app.py`
   - En bas Ã  droite, regarde lâ€™encodage (UTF-8 ou UTF-16)
   - Si ce nâ€™est pas UTF-8, clique dessus â†’ `Reopen with Encoding` â†’ `UTF-8`
   - Ensuite `File â†’ Save with Encoding â†’ UTF-8`

 - **Notepad++** :
   - `Encoding` â†’ `Convert to UTF-8 (without BOM)` â†’ sauvegarder

### CrÃ©er le Dockerfile

Un **Dockerfile** est un fichier texte qui dÃ©crit Ã©tape par Ã©tape comment construire lâ€™image Docker dâ€™une application.  
Il contient les instructions nÃ©cessaires pour crÃ©er un environnement reproductible, portable et prÃªt Ã  exÃ©cuter lâ€™application.

Voici un exemple de Dockerfile et lâ€™explication de chaque ligne :

Dans le mÃªme dossier, crÃ©ez le fichier **Dockerfile** manuellement ou avec : 

```bash
type nul > Dockerfile #sous Windows"
touch Dockerfile #sous Linux
```

Ouvrir le fichier et copier coller cette configuration : 

```Dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY app.py /app
RUN pip install streamlit
EXPOSE 8080
CMD ["streamlit", "run", "app.py", "--server.port=8080", "--server.address=0.0.0.0"]
```

Voici lâ€™explication de chaque ligne :

- `FROM python:3.11-slim`  : Choisit lâ€™image de base. Ici, on utilise Python 3.11 dans une version lÃ©gÃ¨re appelÃ©e *slim*.  
Câ€™est le point de dÃ©part de lâ€™image.
- `WORKDIR /app` :  DÃ©finit le dossier de travail Ã  lâ€™intÃ©rieur du conteneur.  Toutes les commandes suivantes sâ€™exÃ©cuteront dans `/app`.
- `COPY app.py /app`  : Copie le fichier `app.py` depuis la machine hÃ´te vers le dossier `/app` du conteneur.  Cela intÃ¨gre le code de lâ€™application dans lâ€™image.
- `RUN pip install streamlit`  : ExÃ©cute une commande pendant la construction de lâ€™image.  Ici, on installe Streamlit dans lâ€™environnement du conteneur.
- `EXPOSE 8080` : Indique que lâ€™application utilise le port 8080.  Cela ne publie pas le port, mais documente lâ€™usage pour Docker et les utilisateurs.
- `CMD ["streamlit", "run", "app.py", "--server.port=8080", "--server.address=0.0.0.0"]`  : DÃ©finit la commande exÃ©cutÃ©e automatiquement lorsque le conteneur dÃ©marre.  Ici, le conteneur lancera Streamlit et rendra lâ€™application accessible depuis lâ€™extÃ©rieur.


### Construire lâ€™image Docker

Pour transformer un Dockerfile en une image exÃ©cutable, Docker utilise la commande `docker build`.  
Cette Ã©tape lit les instructions du Dockerfile et assemble une image prÃªte Ã  Ãªtre lancÃ©e sous forme de conteneur.
La commande `docker build` sert Ã  :

- lire le Dockerfile prÃ©sent dans le dossier courant  
- tÃ©lÃ©charger les images de base nÃ©cessaires  
- copier les fichiers dans lâ€™image  
- installer les dÃ©pendances  
- prÃ©parer lâ€™environnement dâ€™exÃ©cution  
- produire une image finale que lâ€™on peut lancer avec `docker run`

En rÃ©sumÃ©, elle **compile** lâ€™image Ã  partir du Dockerfile.

```bash
docker build -t my-streamlit-app .
```

- `docker build` : lance la procÃ©dure de construction de lâ€™image  
- `-t my-streamlit-app` : donne un nom (tag) Ã  lâ€™image pour pouvoir lâ€™utiliser plus facilement  
- `.` : indique que le Dockerfile se trouve dans le rÃ©pertoire courant

AprÃ¨s lâ€™exÃ©cution, Docker crÃ©e une image appelÃ©e `my-streamlit-app`.

:warning: Le build dâ€™une image Docker peut prendre plusieurs minutes, surtout si elle tÃ©lÃ©charge des dÃ©pendances ou des images de base, et lâ€™image rÃ©sultante peut Ãªtre assez lourde.

VÃ©rifier que l'image existe : 

```bash
docker images
```

### Lancer le conteneur

```bash
docker run -d -p 8080:8080 my-streamlit-app
```

- `-d` â†’ dÃ©tachÃ©, le conteneur tourne en arriÃ¨re-plan  
- `-p 8080:8080` â†’ mappe le port 8080 du conteneur sur le port 8080 de la VM  

En local, l'application est accessible sur `http://localhost:8080/`.
Dans Play With Docker, cliquez sur le bouton **Open PORT** et tappez **8080** pour accÃ©der Ã  votre application Streamlit.

### En rÃ©sumÃ©

- Le Dockerfile sert Ã  **dÃ©crire la recette complÃ¨te** pour crÃ©er une image.  
- Il garantit que lâ€™environnement est **identique partout**, quel que soit lâ€™ordinateur ou le serveur.  
- Une fois le Dockerfile crÃ©Ã©, on construit lâ€™image avec :  
  `docker build -t my-streamlit-app .`  
- Puis on lance le conteneur avec :  
  `docker run -p 8080:8080 my-streamlit-app`

### Supprimer le conteneur

Docker permet de crÃ©er et gÃ©rer des conteneurs, et parfois il est nÃ©cessaire de les supprimer. Voici les principales mÃ©thodes.

Lister les conteneurs en cours d'exÃ©cution  : 

```bash
docker ps
```

- Si le conteneur nâ€™est pas en cours dâ€™exÃ©cution, il suffit de faire :
```bash
docker rm <container_name_or_id>
```
- Sinon : 
  - Pour un conteneur actif, il faut dâ€™abord lâ€™arrÃªter, puis le supprimer :
```bash
docker stop <container_name_or_id>
docker rm <container_name_or_id>
```

On peut aussi forcer la suppression (mÃªme si le conteneur tourne)

:warning: Utiliser avec prÃ©caution car cela arrÃªte et supprime le conteneur immÃ©diatement :
```bash
docker rm -f <container_name_or_id>
```

### Tableau rÃ©capitulatif des commandes

| Commande | Description |
|----------|-------------|
| docker build -t my-streamlit-app . | Construire lâ€™image Docker |
| docker run -d -p 8080:8080 my-streamlit-app | Lancer le conteneur |
| docker ps | Lister les conteneurs actifs |
| docker ps -a | Lister tous les conteneurs |
| docker logs <id> | Afficher les logs dâ€™un conteneur |
| docker stop <id> | Stopper un conteneur |
| docker rm <id> | Supprimer un conteneur |
| docker container prune | Supprimer tous les conteneurs arrÃªtÃ©s |

### ğŸ’¡ Astuces

- Chaque modification de **app.py** nÃ©cessite de **rebuilder lâ€™image** avec `docker build`  
- Vous pouvez crÃ©er plusieurs conteneurs de la mÃªme image sur diffÃ©rents ports pour tester plusieurs instances  
- Cette configuration est **lÃ©gÃ¨re** et adaptÃ©e Ã  une VM avec **4â€¯Go RAM**

#  Quelques notions de RÃ©seau

## La notion de port sur un PC :

Imagine que ton **ordinateur est comme une maison** :

- Lâ€™ordinateur a une **seule adresse** (câ€™est lâ€™IP) : câ€™est lâ€™Ã©quivalent de lâ€™adresse de ta maison dans la ville.  
- Mais dans cette maison, il y a **plein de portes** : la porte de la cuisine, la porte du salon, la porte de la chambreâ€¦ chacune a une fonction spÃ©cifique.  

Chaque **port** sur lâ€™ordinateur, câ€™est comme une **porte spÃ©ciale de la maison** :  

- Si quelquâ€™un veut tâ€™envoyer un message pour regarder la tÃ©lÃ©, il va frapper Ã  la **porte du salon** (port 80 pour un site web, par exemple).  
- Si quelquâ€™un veut tâ€™envoyer un message pour le courrier Ã©lectronique, il va frapper Ã  la **porte de la salle de courrier** (port 25 pour le mail).  
- Si tu ne veux pas quâ€™on entre dans une piÃ¨ce, tu peux **verrouiller la porte** (le port fermÃ©).  

**Donc, un port, câ€™est juste une porte dâ€™entrÃ©e virtuelle dans ton ordinateur** qui permet Ã  des programmes diffÃ©rents de recevoir des messages diffÃ©rents, mÃªme si tout passe par la mÃªme adresse de la maison.

## Les ports sur le web et en localhost

- **Localhost (127.0.0.1)** = parler Ã  soi-mÃªme dans sa maison.  
- MÃªme en restant chez soi, chaque programme Ã©coute sur **une porte spÃ©cifique** (un port) :  
  - Exemple : ton serveur web local Ã©coute sur le **port 3000**.  
  - Pour y accÃ©der : `http://localhost:3000` â†’ tu ouvres la **porte 3000 de ta maison** pour voir ce qui se passe dans cette piÃ¨ce.  

### En gros

| Concept informatique | MÃ©taphore de la maison |
|--------------------|----------------------|
| Adresse IP / localhost | Adresse de la maison |
| Port | Porte spÃ©cifique de la maison |

**RÃ©sumÃ© :** mÃªme sur ton propre ordinateur, chaque programme a sa **porte** pour recevoir les messages, et tout reste organisÃ© sans se mÃ©langer.

### SchÃ©ma rÃ©capitulatif

Adresse de la maison : 127.0.0.1 (localhost)

````markdown
          [Maison = ton PC]
  ---------------------------------
  |        Salon (Port 80)       |  â† site web
  |        Cuisine (Port 25)     |  â† emails
  |        Bureau (Port 22)      |  â† accÃ¨s Ã  distance
  |        Chambre (Port 3000)   |  â† site local / dev
  ---------------------------------
````

Chaque piÃ¨ce = un programme/service
Chaque porte = un port qui reÃ§oit les messages
Localhost = toi qui parles Ã  ta propre maison

# Gestion des volumes Docker

Les volumes Docker permettent de **stocker des donnÃ©es de maniÃ¨re persistante** hors des conteneurs.  
Sans volume, toutes les donnÃ©es crÃ©Ã©es dans un conteneur disparaissent dÃ¨s que le conteneur est supprimÃ©.

## Pourquoi utiliser des volumes ?

- PrÃ©server les donnÃ©es au-delÃ  du cycle de vie dâ€™un conteneur
- Partager des fichiers entre plusieurs conteneurs
- SÃ©parer le stockage des donnÃ©es et lâ€™image du conteneur
- Faciliter les sauvegardes et migrations

## Types de stockage

### Volumes nommÃ©s
- CrÃ©Ã©s et gÃ©rÃ©s par Docker
- StockÃ©s dans `/var/lib/docker/volumes/`
- Exemple : `mysql_data` pour une base MySQL

### Bind mounts (montage de rÃ©pertoire hÃ´te)
- Lie un dossier du systÃ¨me hÃ´te Ã  un conteneur
- Utile pour le dÃ©veloppement et le partage de fichiers
- Exemple : `-v /home/user/app:/app` dans un `docker run`


## Commandes utiles

### CrÃ©er un volume

```bash
docker volume create nom_du_volume
```

### Lister les volumes

```bash
docker volume ls
```

### Inspecter un volume

```bash
docker volume inspect nom_du_volume
```

### Supprimer un volume

```bash
docker volume rm nom_du_volume
```

:warning: supprimer un volume supprime **toutes les donnÃ©es stockÃ©es**.

## Gestion des volumes Docker avec des fichiers CSV

Les volumes Docker permettent de **stocker des fichiers de maniÃ¨re persistante**, mÃªme si le conteneur est supprimÃ©.  
Pour illustrer cela, on va utiliser un conteneur Python qui gÃ©nÃ¨re des fichiers CSV dans un volume.

### Arborescence du projet

CrÃ©er un dossier de projet contenant :

````markdown
projet-volume/  
- generate_csv.py  
- Dockerfile  
````

Dans cet exemple, on utilise un Dockerfile pour crÃ©er une image Python contenant un script `generate_csv.py`.  
Le conteneur Ã©crit un fichier CSV dans un **volume Docker**, ce qui permet de **persister les donnÃ©es** mÃªme aprÃ¨s la suppression du conteneur.

### PrÃ©parer un script Python

CrÃ©er un fichier `generate_csv.py` :

```python
import csv  
import os  

os.makedirs("/data", exist_ok=True)  

with open("/data/contacts.csv", mode="w", newline="") as f:  
    writer = csv.writer(f)  
    writer.writerow(["Nom", "Email"])  
    writer.writerow(["Alice", "alice@example.com"])  
    writer.writerow(["Bob", "bob@example.com"])  

print("CSV gÃ©nÃ©rÃ© dans /data/contacts.csv")  
```

### CrÃ©er un fichier Dockerfile

```dockerfile
FROM python:3.11-slim
WORKDIR /data
COPY generate_csv.py .
```

Le `.` Ã  la fin signifie : copier generate_csv.py dans le dossier courant du conteneur (/data grÃ¢ce Ã  WORKDIR).

### CrÃ©er et monter un volume Docker

On va utiliser un volume nommÃ© `csv_data` :

```shell
cd projet-volume
docker volume create csv_data
```

### Construire lâ€™image Docker

```shell
docker build -t csv-generator .
```

### Lancer le conteneur pour gÃ©nÃ©rer le CSV

```shell
docker run --rm -v csv_data:/data csv-generator python generate_csv.py
```

- `-v csv_data:/data` â†’ monte le volume pour stocker le CSV  
- `--rm` â†’ supprime le conteneur aprÃ¨s exÃ©cution  
- Le script Ã©crit le fichier `contacts.csv` dans le volume
- 

### VÃ©rifier la persistance

Lancer un nouveau conteneur pour lire le fichier CSV gÃ©nÃ©rÃ© :

```shell
docker run --rm -v csv_data:/data -w /data python:3.11-slim cat contacts.csv
```

- Tu verras le contenu du CSV mÃªme si le conteneur qui lâ€™a crÃ©Ã© a Ã©tÃ© supprimÃ©  
- Cela dÃ©montre la **persistance des donnÃ©es avec les volumes Docker**

### Lister les fichiers dans un volume nommÃ©

```shell
docker run --rm -v csv_data:/data -w /data busybox ls -l
```

- `--rm` : supprime le conteneur aprÃ¨s exÃ©cution  
- `-v csv_data:/data` : monte le volume dans `/data` du conteneur  
- `-w /data` : dÃ©finit le dossier courant du conteneur  
- `busybox` : image lÃ©gÃ¨re pour exÃ©cuter des commandes Unix  
- `ls -l` : liste les fichiers avec dÃ©tails

### Explorer le volume en mode interactif

```shell
docker run --rm -it -v csv_data:/data -w /data busybox sh
```

- `-it` : mode interactif + terminal  
- `sh` : ouvre un shell dans le conteneur

Une fois Ã  lâ€™intÃ©rieur, tu peux utiliser :

- `ls` : lister les fichiers  
- `ls -l` : lister avec dÃ©tails  
- `cat contacts.csv` : afficher le contenu dâ€™un fichier  

Tape `exit` pour quitter le conteneur.

### Bonnes pratiques

- Utiliser des volumes pour toutes les donnÃ©es importantes (CSV, bases, logsâ€¦)  
- Nommer les volumes de maniÃ¨re explicite pour Ã©viter les confusions (`csv_data`, `mysql_data`)  
- Supprimer les volumes inutilisÃ©s avec `docker volume prune`  

## GÃ©nÃ©rer un CSV avec Docker et monter un dossier local

Cette mÃ©thode utilise un **bind mount** pour stocker les fichiers CSV directement sur le systÃ¨me de fichiers de l'hÃ´te.

### Modifier le script `generate_csv.py`

```python
import csv  
import os  

# CrÃ©er le dossier de sortie dans le conteneur
os.makedirs("/data/output", exist_ok=True)

with open("/data/output/contacts.csv", mode="w", newline="") as f:  
    writer = csv.writer(f)  
    writer.writerow(["Nom", "Email"])  
    writer.writerow(["Alice", "alice@example.com"])  
    writer.writerow(["Bob", "bob@example.com"])

print("CSV gÃ©nÃ©rÃ© dans /data/output/contacts.csv")
```

### PrÃ©parer un dossier local pour stocker les CSV

Par exemple, crÃ©er un dossier `csv_output` dans `projet-volume/` :

```shell
mkdir csv_output
```

### Construire lâ€™image Docker


```shell
docker build -t csv-generator-local .
```

### Lancer le conteneur Python avec un bind mount

Pour Linux : 

```shell
docker run --rm -v $(pwd)/csv_output:/data csv-generator-local python generate_csv.py
```

Pour Windows PowerShell: 

```shell
docker run --rm -v ${PWD}/csv_output:/data/output csv-generator-local python generate_csv.py
```

- `-v $(pwd)/csv_output:/data` : lie le dossier local `csv_output` au dossier `/data` dans le conteneur  
- `-w /data` : dÃ©finit le dossier courant dans le conteneur  
- Le script Ã©crit `contacts.csv` dans `/data` â†’ apparaÃ®t automatiquement dans `csv_output` sur lâ€™hÃ´te

### VÃ©rifier le fichier sur lâ€™hÃ´te

```shell
ls csv_output
```

- Le fichier `contacts.csv`est gÃ©nÃ©rÃ©  
- Le fichier est persistant et accessible directement depuis ton systÃ¨me de fichiers


# Introduction Ã  Docker Compose

## Objectif

- Lancer MySQL et Streamlit avec Docker Compose  
- Connecter Streamlit Ã  la base MySQL  
- InsÃ©rer des donnÃ©es via un formulaire web  
- Tester lâ€™ensemble en local, sans Docker Swarm  

Docker Compose permet de dÃ©finir et lancer plusieurs services Ã  partir d'un seul fichier `docker-compose.yml`.  
Chaque service reprÃ©sente un conteneur (ex : MySQL, une application web, un backendâ€¦).  
Compose gÃ¨re automatiquement le rÃ©seau, les volumes et l'ordre de dÃ©marrage.

Dans notre projet, le fichier `docker-compose.yml` contient deux services :

- `mysql-db` : la base de donnÃ©es MySQL  
- `streamlit-app` : l'application web

Compose crÃ©e aussi un rÃ©seau interne pour que les conteneurs puissent communiquer entre eux en utilisant leurs noms de service comme hostname.

## Arborescence du projet

CrÃ©er un dossier de projet contenant :

````markdown
projet-streamlit-mysql/  
- app.py  
- requirements.txt  
- Dockerfile  
- docker-compose.yaml  
````

## Fichier app.py

```python
import streamlit as st  
import mysql.connector  

conn = mysql.connector.connect(  
    host="mysql-db",  
    user="user",  
    password="password",  
    database="contactsdb"  
)  
cursor = conn.cursor()  

st.title("Formulaire de contact")  
name = st.text_input("Nom")  
email = st.text_input("Email")  
message = st.text_area("Message")  

if st.button("Envoyer"):  
    if name and email and message:  
        cursor.execute(  
            "INSERT INTO contacts (name,email,message) VALUES (%s,%s,%s)",  
            (name, email, message)  
        )  
        conn.commit()  
        st.success("Message ajoutÃ© !")  
    else:  
        st.error("Remplissez tous les champs !")  
```

## Fichier requirements.txt

```txt
streamlit  
mysql-connector-python  
```


## Fichier Dockerfile

```dockerfile
FROM python:3.11-slim  
WORKDIR /app  
COPY requirements.txt ./  
RUN pip install --no-cache-dir -r requirements.txt  
COPY . .  
CMD ["streamlit","run","app.py","--server.port=8501","--server.address=0.0.0.0"]  
```

## Fichier docker-compose.yml

```yaml
version: "3.9"  

services:  

  mysql-db:  
    image: mysql:8.0  
    container_name: mysql-db  
    environment:  
      MYSQL_ROOT_PASSWORD: root  
      MYSQL_DATABASE: contactsdb  
      MYSQL_USER: user  
      MYSQL_PASSWORD: password  
    ports:  
      - "3306:3306"  
    volumes:  
      - mysql_data:/var/lib/mysql  
    networks:  
      - app-network  

  streamlit-app:  
    build: .  
    container_name: streamlit-app  
    depends_on:  
      - mysql-db  
    ports:  
      - "8501:8501"  
    networks:  
      - app-network  

networks:  
  app-network:  

volumes:  
  mysql_data:  
```

## CrÃ©er la table MySQL

Avant de dÃ©marrer toute l'application, il peut Ãªtre utile de lancer seulement le service MySQL, par exemple pour crÃ©er la base ou la table.
La commande suivante dÃ©marre uniquement le service `mysql-db` :

```shell
docker compose up mysql-db -d  
```

- `mysql-db` : nom du service Ã  lancer  
- `-d` : exÃ©cution en mode dÃ©tachÃ© (le conteneur tourne en arriÃ¨re-plan)

:bulb: Une fois MySQL lancÃ©, il devient accessible depuis les autres services Docker via le hostname `mysql-db`, et depuis lâ€™hÃ´te en utilisant le port 3306 si celui-ci est exposÃ© dans le fichier Compose.

Une fois le service MySQL lancÃ© avec Docker Compose, il peut Ãªtre utile dâ€™ouvrir une session MySQL directement Ã  lâ€™intÃ©rieur du conteneur.  
Cela permet de vÃ©rifier lâ€™Ã©tat de la base, de crÃ©er des tables ou de consulter les donnÃ©es.

La commande suivante ouvre un terminal interactif Ã  lâ€™intÃ©rieur du conteneur `mysql-db`  
et lance le client MySQL connectÃ© Ã  la base `contactsdb` :

```shell
docker exec -it mysql-db mysql -h mysql-db -uuser -ppassword contactsdb
```

- `docker exec` : exÃ©cute une commande dans un conteneur en cours dâ€™exÃ©cution  
- `-it` : mode interactif + terminal  
- `mysql-db` : nom du conteneur oÃ¹ exÃ©cuter la commande  
- `mysql` : lance le client MySQL installÃ© dans le conteneur  
- `-h mysql-db` : indique lâ€™hÃ´te MySQL (le nom du service dans Docker Compose)  
- `-uuser` : nom dâ€™utilisateur MySQL  
- `-ppassword` : mot de passe MySQL  
- `contactsdb` : base de donnÃ©es Ã  utiliser

CrÃ©er la table :  

```sql
CREATE TABLE contacts (  
    id INT AUTO_INCREMENT PRIMARY KEY,  
    name VARCHAR(255),  
    email VARCHAR(255),  
    message TEXT  
);
```  

```shell
exit  
```

## Lancer toute lâ€™application

Une fois que tous les fichiers du projet sont prÃªts (Dockerfile, app.py, requirements, docker-compose.yml), Docker Compose peut construire les images et dÃ©marrer lâ€™ensemble des services.

```shell
docker compose up --build
```

Docker Compose :
- crÃ©e les conteneurs  
- met en place le rÃ©seau interne  
- attache les logs des services au terminal  
- dÃ©marre MySQL puis lâ€™application Streamlit qui dÃ©pend de MySQL


Ouvrir Streamlit sur : http://localhost:8501  


## VÃ©rifier les donnÃ©es

:warning: l'application MySQL est ouvert en intÃ©ractif + terminal c'est pourquoi il faut ouvrir un nouveau terminal pour la commande suivante : 

```shell
docker exec -it mysql-db mysql -h mysql-db -uuser -ppassword contactsdb
```

```sql
SELECT * FROM contacts;  
```

:bulb: Pourquoi `docker compose up --build` ne rÃ©initialise pas MySQL ? Lorsque tu relances lâ€™application avec `docker compose up --build`, MySQL ne repart pas de zÃ©ro.  La raison est simple : Docker Compose utilise un **volume persistant** pour stocker les donnÃ©es MySQL.

Dans le fichier `docker-compose.yml`, on trouve :

```yaml
- mysql_data:/var/lib/mysql
```

Ce volume `mysql_data` contient toutes les donnÃ©es MySQL : la base, les tables et leur contenu.  
Les volumes Docker sont conÃ§us pour **survivre** aux redÃ©marrages et aux reconstructions dâ€™images.  
Ainsi, mÃªme si lâ€™on reconstruit lâ€™image ou recrÃ©e les conteneurs, MySQL retrouve automatiquement ses donnÃ©es.


## Nettoyer

```shell
docker compose down  
docker compose down -v
```

La commande `docker compose down -v` arrÃªte les conteneurs, supprime le rÃ©seau et **efface les volumes**, ce qui vide totalement MySQL.  
Au prochain dÃ©marrage, MySQL sera comme neuf.


# Introduction Ã  Docker Swarm Mode

## DÃ©couverte

Jusquâ€™ici, nous avons utilisÃ© **Docker sur un seul hÃ´te**, avec quelques conteneurs isolÃ©s.  
Mais en production, une application peut impliquer **des dizaines ou centaines de conteneurs** : base de donnÃ©es, front-end, API, workers, etc.  
Pour coordonner tout cela, il faut un outil dâ€™orchestration.

Docker propose **deux outils principaux** :
- **Docker Compose** â†’ pour gÃ©rer plusieurs conteneurs sur une mÃªme machine.
- **Docker Swarm Mode** â†’ pour gÃ©rer plusieurs *machines Docker* en cluster, avec haute disponibilitÃ© et scalabilitÃ©.

## Docker Swarm Mode : quâ€™est-ce que câ€™est ?

**Docker Swarm** permet de :
- DÃ©ployer et coordonner plusieurs nÅ“uds (machines Docker).
- RÃ©partir automatiquement les conteneurs entre les nÅ“uds.
- Assurer la **haute disponibilitÃ©** (HA) avec plusieurs *managers*.
- Offrir le **scaling** et le **load balancing** intÃ©grÃ©s.

Un cluster Swarm contient :
- Des **nÅ“uds managers** (gÃ¨rent le cluster, peuvent aussi exÃ©cuter des conteneurs).
- Des **nÅ“uds workers** (exÃ©cutent les conteneurs selon les ordres des managers).

### RÃ´les des nÅ“uds
- **Manager**
  - Responsable de la **gestion du cluster** : planification des services, gestion de lâ€™Ã©tat des nÅ“uds et des tÃ¢ches.  
  - Prend les dÃ©cisions sur oÃ¹ et combien de containers dÃ©ployer.  
  - Peut aussi exÃ©cuter des containers, mais son rÃ´le principal est administratif.  
- **Worker**
  - ExÃ©cute les **containers assignÃ©s** par le manager.  
  - Ne prend pas de dÃ©cision sur la planification.  
  
### IntÃ©rÃªt
- Permet de **scaler facilement** les services (augmenter/diminuer les rÃ©plicas).  
- Assure la **haute disponibilitÃ©** : si un nÅ“ud worker tombe, le manager redÃ©ploie les containers sur dâ€™autres nÅ“uds.  
- Le manager peut avoir **plusieurs instances** pour garantir la tolÃ©rance aux pannes. 
  
SchÃ©ma mental : le manager est le "chef dâ€™orchestre", les workers sont les musiciens qui exÃ©cutent les tÃ¢ches.

## DÃ©ploiement et Scaling dâ€™un Service Web

### Objectif

Ce tutoriel montre comment :

- CrÃ©er un cluster Swarm (plusieurs nÅ“uds Docker qui coopÃ¨rent)  
- DÃ©ployer un service web distribuÃ© (Nginx)  
- Scaler ce service pour gÃ©rer plus de charge  
- Comprendre comment Docker Swarm assure la rÃ©partition de charge et la tolÃ©rance aux pannes  

### Lancer lâ€™environnement

:warning: Pour simplifier ce cas pratique, *utilisez Play With Docker* plutÃ´t que votre machine local, cela permettra de crÃ©er des clusters plus facilement et rapidement.

1. Va sur [Play With Docker](https://labs.play-with-docker.com/).  
2. Clique sur **Start**, puis **Add New Instance** â†’ tu obtiens une VM Linux (`node1`).  
3. Ajoute deux autres instances avec **Add New Instance** â†’ tu as maintenant 3 nÅ“uds : `node1`, `node2`, `node3`.  

### Initialiser le Swarm

Sur le nÅ“ud manager (**node1**) :

```bash
docker swarm init --advertise-addr $(hostname -i)
```

Docker crÃ©e le cluster Swarm et tâ€™affiche une commande `docker swarm join` Ã  exÃ©cuter sur les autres nÅ“uds.

Sur les autres nÅ“uds (**node2, node3, â€¦**) :

```bash
docker swarm join --token <token> <IP_manager>:2377)
```

### VÃ©rifier les nÅ“uds du cluster

Sur le manager :

```bash
docker node ls
```

Exemple de sortie :

````markdown
ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS  
kytp4gq5mrvmdbb0qpifdxeiv *  node1     Ready   Active        Leader  
lz1j4d6290j8lityk4w0cxls5    node2     Ready   Active  
qpl9d95hd8z0l1aox6uwb90d7    node3     Ready   Active  
````

Le symbole * indique le manager.  
Seul le leader peut exÃ©cuter des commandes administratives comme `docker node ls`.

### CrÃ©er un service web

CrÃ©ons un service **Nginx** exposÃ© sur le port 80 :

```bash
docker service create -p 80:80 --name web nginx:latest
```

Puis vÃ©rifie quâ€™il est bien en cours dâ€™exÃ©cution :

```bash
docker service ls
```

Exemple :

````markdown
ID             NAME      MODE         REPLICAS   IMAGE           PORTS  
9h8fz9rhv7uk   web       replicated   1/1        nginx:latest    *:80->80/tcp
````

### Tester le service

Sur nâ€™importe quel nÅ“ud du cluster :

```bash
curl http://localhost:80
```

Tu devrais voir la page par dÃ©faut de **Nginx**.

### Scaler (augmenter le nombre dâ€™instances)

Pour ajouter plus dâ€™instances du service :

```bash
docker service scale web=15
```

Docker va automatiquement rÃ©partir les 15 containers Nginx sur les diffÃ©rents nÅ“uds disponibles.

VÃ©rifie leur rÃ©partition :

```bash
docker service ps web
```

Exemple :

````markdown
ID             NAME      IMAGE           NODE      DESIRED STATE   CURRENT STATE  
t5h2x3l7j9z0   web.1     nginx:latest    node1     Running         Running 1m ago  
hj2a7c6g2s8l   web.2     nginx:latest    node2     Running         Running 1m ago  
f9q3d8h4k2a7   web.3     nginx:latest    node3     Running         Running 1m ago  
...
````

### Load Balancing Automatique

Docker Swarm gÃ¨re automatiquement la rÃ©partition du trafic entre tous les containers du service.  
MÃªme si ton service expose le port 80 sur un seul nÅ“ud, Swarm redirige les connexions vers nâ€™importe quelle instance disponible.

Cela signifie que tous les containers web participent Ã  servir les utilisateurs, mÃªme sâ€™ils sont sur diffÃ©rents nÅ“uds.

### TolÃ©rance aux pannes

Si un nÅ“ud tombe, Docker redÃ©ploie automatiquement ses containers sur dâ€™autres nÅ“uds :

```bash
docker node update --availability drain node2
```

Cela simule la mise hors service de node2.  

VÃ©rifie ensuite :

```bash
docker service ps web
```

Les containers qui Ã©taient sur node2 ont Ã©tÃ© automatiquement replacÃ©s sur node1 et node3.

Pour le remettre en ligne :

```bash
docker node update --availability active node2
docker service ps web
```


### RÃ©duire le nombre dâ€™instances

Pour rÃ©duire la charge :

```bash
docker service scale web=10
docker service ps web
```

Swarm va supprimer 5 containers (au hasard), tout en gardant le service fonctionnel.

### ComprÃ©hension du fonctionnement

#### Swarm = un cluster de serveurs Docker

Swarm transforme plusieurs hÃ´tes Docker en un seul cluster logique.  
Le manager orchestre les dÃ©ploiements, les workers hÃ©bergent les containers.

#### Service = application distribuÃ©e

Un â€œserviceâ€ est une application dÃ©clarÃ©e (ex: Nginx).  
Swarm la dÃ©ploie sous forme de rÃ©plicas (plusieurs containers identiques).

#### Scaling = augmenter la capacitÃ©

```bash
docker service scale web=15
docker service ps web
```

signifie : "Lance 15 serveurs Nginx identiques rÃ©partis dans le cluster."

Plus de rÃ©plicas = plus de puissance pour servir des utilisateurs simultanÃ©s.

#### Load Balancing intÃ©grÃ©

Swarm agit comme un rÃ©partiteur de charge interne :  
Le port 80 du cluster redirige les connexions vers nâ€™importe quel replica.

Cela Ã©quilibre automatiquement le trafic entre les containers.  
Aucun proxy manuel nâ€™est nÃ©cessaire.

#### RÃ©silience

Swarm surveille lâ€™Ã©tat des containers.  
Sâ€™il dÃ©tecte une panne, il redÃ©ploie les instances ailleurs.  
Câ€™est le principe de la **haute disponibilitÃ© (HA)**.

#### Supprimer le service

Pour supprimer le service **web** :

```bash
docker service rm web
```

VÃ©rifie ensuite quâ€™il a bien Ã©tÃ© supprimÃ© :

```bash
docker service ls
```

### En rÃ©sumÃ©

| Fonction | Commande | Explication |
|-----------|-----------|-------------|
| CrÃ©er le cluster | docker swarm init | DÃ©marre Swarm et dÃ©finit le manager |
| Joindre un nÅ“ud | docker swarm join | Ajoute un worker au cluster |
| Lister les nÅ“uds | docker node ls | VÃ©rifie les membres du cluster |
| DÃ©ployer un service | docker service create | Lance une app dans le cluster |
| Scaler le service | docker service scale web=15 | Multiplie le nombre dâ€™instances |
| RÃ©partir la charge | (automatique) | Load balancing intÃ©grÃ© |
| GÃ©rer les pannes | docker node update --availability drain | DÃ©place les services en cas de problÃ¨me |


### Exemple visuel

```
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Manager   â”‚
          â”‚  node1     â”‚
          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚              â”‚                â”‚
â–¼              â–¼                â–¼
node1         node2            node3
(web.1)       (web.2)          (web.3)
(web.4)       (web.5)          (web.6)
   â”‚             â”‚                â”‚
   â””â”€â”€â”€â”€â”€â”€â”€ Load Balancer â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
          Utilisateurs ğŸŒ
```


### Ã€ retenir

- Chaque container = une instance serveur, pas un utilisateur.  
- Les utilisateurs se connectent Ã  travers le port exposÃ©, et Swarm distribue leurs requÃªtes.  
- Tu peux donc simuler plus de serveurs web (scaling), pas plus dâ€™utilisateurs.  
- Swarm rend ton application plus robuste, scalable et hautement disponible.  


## Formulaire Web Streamlit + MySQL  avec Play With Docker

### Objectif

- CrÃ©er un cluster Swarm (1 manager + 2 workers) sur PWD  
- DÃ©ployer un service MySQL pour stocker les donnÃ©es  
- DÃ©ployer un service Streamlit avec un formulaire web  
- InsÃ©rer les infos du formulaire dans la base MySQL  
- Tester la communication entre les containers et observer le fonctionnement du Swarm  

### PrÃ©parer lâ€™environnement PWD

CrÃ©e 3 instances dans PWD :  

- node1 â†’ manager  
- node2 â†’ worker  
- node3 â†’ worker  

Sur **node1 (manager)**, initialise le Swarm :

```bash
docker swarm init --advertise-addr $(hostname -i)
```

Copie la commande `docker swarm join` affichÃ©e par Docker.  

Sur **node2** et **node3 (workers)**, colle la commande join pour les joindre au Swarm.  

VÃ©rifie sur **node1** que tous les nÅ“uds sont prÃªts :

```bash
docker node ls
```

### CrÃ©er un rÃ©seau overlay

Sur **node1 (manager)** :

```bash
docker network create --driver overlay app-network
```

Tous les services doivent Ãªtre sur ce rÃ©seau pour communiquer entre eux.

### DÃ©ployer MySQL

Sur **node1** :

```bash
docker service create --name mysql-db --network app-network --env MYSQL_ROOT_PASSWORD=root --env MYSQL_DATABASE=contactsdb --env MYSQL_USER=user --env MYSQL_PASSWORD=password mysql:8.0
```

- Nom du service : **mysql-db**  
- Base : **contactsdb**  
- Utilisateur : **user / password**  

Tester MySQL :  

RÃ©cupÃ¨re le container MySQL :

```bash
docker ps
```

Connecte-toi Ã  MySQL :  

```bash
docker exec -it <container_id> mysql -uuser -ppassword contactsdb
```

CrÃ©e la table `contacts` :

```bash
CREATE TABLE contacts (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(255),
    email VARCHAR(255),
    message TEXT
);
```

puis tappez `exit`.

### PrÃ©parer lâ€™application Streamlit

Sur **node1**, crÃ©e un dossier `app` et les fichiers nÃ©cessaires depuis le terminal : 

```bash
mkdir app
cd app
```

#### CrÃ©er `app.py` 

CrÃ©er le fichier avec la commande `touch app.py` puis dans l'editeur de fichier PWD copier coller le script ci-dessous.

```python
import streamlit as st
import mysql.connector

conn = mysql.connector.connect(host="mysql-db", user="user", password="password", database="contactsdb")
cursor = conn.cursor()

st.title("Formulaire de contact")
name = st.text_input("Nom")
email = st.text_input("Email")
message = st.text_area("Message")

if st.button("Envoyer"):
    if name and email and message:
        cursor.execute("INSERT INTO contacts (name,email,message) VALUES (%s,%s,%s)", (name,email,message))
        conn.commit()
        st.success("Message ajoutÃ© !")
    else:
        st.error("Remplissez tous les champs !")
```


#### CrÃ©er `requirements.txt` 

CrÃ©er le fichier avec la commande `touch requirements.txt` puis dans l'editeur de fichier PWD copier coller le script ci-dessous.

```txt
streamlit
mysql-connector-python
```

#### CrÃ©er `Dockerfile`

CrÃ©er le fichier avec la commande `touch Dockerfile` puis dans l'editeur de fichier PWD copier coller le script ci-dessous.

```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
CMD ["streamlit","run","app.py","--server.port=8501","--server.address=0.0.0.0"]
```

### Construire lâ€™image Streamlit

Sur **node1** :

```bash
docker build -t streamlit-app .
```

### DÃ©ployer le service Streamlit sur le Swarm

Sur PWD, lâ€™image est locale sur node1 seulement.  
Les autres nÅ“uds nâ€™ont pas lâ€™image et ne peuvent pas dÃ©marrer le container.  
Pour que Ã§a fonctionne, on force le service Ã  tourner sur **node1** :

```bash
docker service create --name streamlit-app --network app-network --replicas 1 -p 8501:8501 --constraint 'node.hostname==node1' streamlit-app
```

- `--constraint 'node.hostname==node1'` â†’ force le container sur node1  
- `-p 8501:8501` â†’ expose Streamlit pour le navigateur  

### Tester lâ€™application

Depuis le navigateur PWD : ouvrir le port `8501`

- Remplir le formulaire et clique sur â€œEnvoyerâ€  
- VÃ©rifir que les donnÃ©es ont Ã©tÃ© ajoutÃ©es dans MySQL :

```bash
docker exec -it $(docker ps -q -f name=mysql-db) mysql -uuser -ppassword contactsdb
```

```bash
SELECT * FROM contacts;
```

Tu dois voir le nom, lâ€™email et le message ajoutÃ©s depuis Streamlit.

### Nettoyer

```bash
docker service rm streamlit-app  
```

```bash
docker service rm mysql-db  
```

```bash
docker network rm app-network
```

### Conseils PWD

- ExÃ©cuter toutes les commandes Swarm sur le **manager (node1)**  
- Les services doivent Ãªtre sur le mÃªme **rÃ©seau overlay**  
- Les volumes MySQL sont temporaires sur PWD  
- Streamlit peut Ãªtre scalÃ©, mais avec image locale sur PWD, il faut forcer le nÅ“ud ou pousser sur Docker Hub  

### SchÃ©ma visuel du TP

```
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  Manager   â”‚
          â”‚  node1     â”‚
          â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                â”‚
      node2             node3
     (worker)          (worker)
       â”‚                â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
                    â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚    Overlay       â”‚
           â”‚   app-network    â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  MySQL DB   â”‚        â”‚ Streamlit Appâ”‚
   â”‚ mysql-db    â”‚        â”‚ streamlit-appâ”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


# Mini-projet Docker : Extraction des donnÃ©es DPE par dÃ©partement

## Objectif pÃ©dagogique

Ce mini-projet a pour but de mettre en pratique les compÃ©tences Docker et Python acquises dans le TP prÃ©cÃ©dent.  
Les Ã©tudiants devront :  

- Interroger lâ€™API DPE de lâ€™ADEME pour plusieurs dÃ©partements  
- Stocker les rÃ©sultats dans des fichiers Parquet  
- ExÃ©cuter un conteneur par dÃ©partement pour isoler le traitement  
- Utiliser un volume local pour persister les fichiers sur lâ€™hÃ´te  

Ce projet combine **Docker, Python, volumes/bind mounts, et paramÃ©trisation par dÃ©partement**.

## Consignes gÃ©nÃ©rales

1. **ParamÃ©trisation par dÃ©partement**  
   - Fournir une liste de dÃ©partements Ã  traiter (ex. : 75, 69, 13)  
   - Chaque conteneur doit rÃ©cupÃ©rer le dÃ©partement via une variable dâ€™environnement ou un paramÃ¨tre  

2. **Isolation avec Docker**  
   - Construire une image Docker contenant le script Python qui interroge lâ€™API et Ã©crit un fichier Parquet  
   - Lancer un conteneur **par dÃ©partement**, pour gÃ©nÃ©rer le fichier correspondant  

3. **Persistance des fichiers**  
   - CrÃ©er un dossier local sur lâ€™hÃ´te (ex. `dpe_output`)  
   - Monter ce dossier dans chaque conteneur pour stocker les fichiers Parquet  
   - VÃ©rifier que les fichiers gÃ©nÃ©rÃ©s sont accessibles aprÃ¨s suppression des conteneurs  

4. **Organisation et bonnes pratiques**  
   - Le script Python doit crÃ©er le dossier de sortie dans le conteneur si nÃ©cessaire  
   - Rebuild de lâ€™image Docker nÃ©cessaire si le script ou Dockerfile est modifiÃ©  
   - Ne pas monter le dossier `/data` de lâ€™image directement pour ne pas Ã©craser le script  
   - Monter un **sous-dossier** pour la sortie afin dâ€™Ã©viter les conflits  

5. **ExÃ©cution parallÃ¨le**  
   - Les conteneurs peuvent Ãªtre exÃ©cutÃ©s en parallÃ¨le
   - Chaque conteneur doit produire un fichier Parquet distinct correspondant au dÃ©partement traitÃ©  


## Livrables attendus

- Un **Dockerfile** fonctionnel contenant le script Python  
- Un **script Python** paramÃ©trÃ© pour interroger lâ€™API DPE selon le dÃ©partement  
- Un **dossier local** rempli de fichiers Parquet (`dpe_<departement>.parquet`)  
- Une courte documentation expliquant :  
  - Comment exÃ©cuter les conteneurs  
  - Comment vÃ©rifier la prÃ©sence et le contenu des fichiers  
  - Comment ajouter de nouveaux dÃ©partements Ã  traiter  

## Points pÃ©dagogiques visÃ©s

- ComprÃ©hension des **conteneurs Docker et des volumes/bind mounts**  
- ParamÃ©trisation et rÃ©utilisation dâ€™images Docker pour plusieurs cas  
- Gestion de donnÃ©es externes (API) et persistance sur lâ€™hÃ´te  
- Organisation de traitements indÃ©pendants pour plusieurs dÃ©partements  
- Workflow complet **dÃ©veloppement â†’ build â†’ exÃ©cution â†’ persistance**
